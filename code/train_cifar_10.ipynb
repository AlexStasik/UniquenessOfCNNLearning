{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "input_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_model():\n",
    "    keras.backend.clear_session()\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, kernel_size=(3,3), strides=(1, 1), activation='relu')(inputs)\n",
    "    x = Conv2D(32, kernel_size=(3,3), strides=(1, 1), activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), strides=(1, 1), activation='relu')(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), strides=(1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 890,410\n",
      "Trainable params: 890,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 103s 265ms/step - loss: 1.9766 - acc: 0.2751 - val_loss: 1.6448 - val_acc: 0.4243\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 104s 266ms/step - loss: 1.5726 - acc: 0.4299 - val_loss: 1.3144 - val_acc: 0.5369\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 103s 262ms/step - loss: 1.3945 - acc: 0.4971 - val_loss: 1.1924 - val_acc: 0.5785\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 102s 261ms/step - loss: 1.2793 - acc: 0.5425 - val_loss: 1.1447 - val_acc: 0.5956\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 101s 257ms/step - loss: 1.1859 - acc: 0.5785 - val_loss: 1.0659 - val_acc: 0.6255\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 108s 277ms/step - loss: 1.1162 - acc: 0.6037 - val_loss: 0.9839 - val_acc: 0.6575\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 107s 275ms/step - loss: 1.0580 - acc: 0.6283 - val_loss: 0.9044 - val_acc: 0.6807\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 99s 254ms/step - loss: 1.0068 - acc: 0.6465 - val_loss: 0.8600 - val_acc: 0.6985\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 97s 249ms/step - loss: 0.9700 - acc: 0.6613 - val_loss: 0.8287 - val_acc: 0.7087\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 101s 259ms/step - loss: 0.9372 - acc: 0.6723 - val_loss: 0.8078 - val_acc: 0.7197\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 107s 273ms/step - loss: 0.9076 - acc: 0.6819 - val_loss: 0.7962 - val_acc: 0.7169\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 100s 257ms/step - loss: 0.8814 - acc: 0.6914 - val_loss: 0.8612 - val_acc: 0.7015\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 100s 256ms/step - loss: 0.8642 - acc: 0.6990 - val_loss: 0.8196 - val_acc: 0.7149\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 100s 255ms/step - loss: 0.8492 - acc: 0.7028 - val_loss: 0.7493 - val_acc: 0.7367\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 96s 247ms/step - loss: 0.8251 - acc: 0.7109 - val_loss: 0.7041 - val_acc: 0.7538\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 97s 247ms/step - loss: 0.8117 - acc: 0.7169 - val_loss: 0.7476 - val_acc: 0.7398\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 98s 250ms/step - loss: 0.8084 - acc: 0.7186 - val_loss: 0.6798 - val_acc: 0.7623\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 102s 260ms/step - loss: 0.7880 - acc: 0.7247 - val_loss: 0.6714 - val_acc: 0.7679\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 98s 249ms/step - loss: 0.7755 - acc: 0.7302 - val_loss: 0.6982 - val_acc: 0.7573\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 102s 260ms/step - loss: 0.7628 - acc: 0.7360 - val_loss: 0.6464 - val_acc: 0.7777\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 102s 261ms/step - loss: 0.7552 - acc: 0.7371 - val_loss: 0.6842 - val_acc: 0.7577\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 100s 255ms/step - loss: 0.7497 - acc: 0.7385 - val_loss: 0.6766 - val_acc: 0.7673\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 97s 248ms/step - loss: 0.7328 - acc: 0.7463 - val_loss: 0.7344 - val_acc: 0.7476\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 97s 248ms/step - loss: 0.7314 - acc: 0.7460 - val_loss: 0.6744 - val_acc: 0.7632\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 98s 250ms/step - loss: 0.7236 - acc: 0.7499 - val_loss: 0.6805 - val_acc: 0.7664\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.7154 - acc: 0.7525 - val_loss: 0.7561 - val_acc: 0.7469\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 95s 244ms/step - loss: 0.7069 - acc: 0.7537 - val_loss: 0.7505 - val_acc: 0.7462\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 98s 250ms/step - loss: 0.7038 - acc: 0.7558 - val_loss: 0.5769 - val_acc: 0.8052\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 104s 267ms/step - loss: 0.6976 - acc: 0.7599 - val_loss: 0.5791 - val_acc: 0.7978\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6925 - acc: 0.7601 - val_loss: 0.6102 - val_acc: 0.7920\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6887 - acc: 0.7610 - val_loss: 0.6067 - val_acc: 0.7912\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6791 - acc: 0.7666 - val_loss: 0.6509 - val_acc: 0.7756\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6780 - acc: 0.7655 - val_loss: 0.5769 - val_acc: 0.8052\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6742 - acc: 0.7693 - val_loss: 0.6690 - val_acc: 0.7758\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6690 - acc: 0.7680 - val_loss: 0.6483 - val_acc: 0.7802\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6684 - acc: 0.7701 - val_loss: 0.6174 - val_acc: 0.7853\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6662 - acc: 0.7702 - val_loss: 0.5612 - val_acc: 0.8097\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6611 - acc: 0.7740 - val_loss: 0.6470 - val_acc: 0.7817\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6575 - acc: 0.7744 - val_loss: 0.5491 - val_acc: 0.8130\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6543 - acc: 0.7754 - val_loss: 0.5863 - val_acc: 0.8051\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 95s 242ms/step - loss: 0.6508 - acc: 0.7735 - val_loss: 0.6282 - val_acc: 0.7877\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 95s 242ms/step - loss: 0.6516 - acc: 0.7750 - val_loss: 0.6016 - val_acc: 0.7989\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 95s 242ms/step - loss: 0.6443 - acc: 0.7769 - val_loss: 0.6013 - val_acc: 0.8005\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 95s 242ms/step - loss: 0.6447 - acc: 0.7794 - val_loss: 0.5832 - val_acc: 0.8038\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6408 - acc: 0.7803 - val_loss: 0.6560 - val_acc: 0.7867\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6401 - acc: 0.7788 - val_loss: 0.5608 - val_acc: 0.8120\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6366 - acc: 0.7798 - val_loss: 0.6024 - val_acc: 0.7980\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6391 - acc: 0.7824 - val_loss: 0.5587 - val_acc: 0.8112\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 95s 243ms/step - loss: 0.6370 - acc: 0.7842 - val_loss: 0.6143 - val_acc: 0.7918\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 95s 242ms/step - loss: 0.6324 - acc: 0.7841 - val_loss: 0.6663 - val_acc: 0.7831\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model = set_up_model()\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train,  batch_size=batch_size),\n",
    "                  epochs=epochs,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
